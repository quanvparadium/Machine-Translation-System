{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rHwty3aI2a-",
        "outputId": "082b3187-580a-47ef-8a95-37276f4a5f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Machine-Translation-System'...\n",
            "remote: Enumerating objects: 1249, done.\u001b[K\n",
            "remote: Counting objects: 100% (244/244), done.\u001b[K\n",
            "remote: Compressing objects: 100% (147/147), done.\u001b[K\n",
            "remote: Total 1249 (delta 84), reused 224 (delta 69), pack-reused 1005\u001b[K\n",
            "Receiving objects: 100% (1249/1249), 40.74 MiB | 14.46 MiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/quanvparadium/Machine-Translation-System.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Machine-Translation-System"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPOVbvCxI499",
        "outputId": "e9fc11a6-054f-4262-c63d-b6e43037ba83"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Machine-Translation-System\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qgdOdY0gJXgG",
        "outputId": "35260bc7-f442-47da-d812-c74ed588d340"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.1.0+cu118)\n",
            "Collecting tqdm==4.65.0 (from -r requirements.txt (line 6))\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urbans (from -r requirements.txt (line 9))\n",
            "  Downloading urbans-0.0.1-py3-none-any.whl (10 kB)\n",
            "Collecting bs4 (from -r requirements.txt (line 12))\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (3.8.1)\n",
            "Collecting fsspec==2023.9.2 (from -r requirements.txt (line 16))\n",
            "  Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets==2.14.6 (from -r requirements.txt (line 17))\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.97 (from -r requirements.txt (line 18))\n",
            "  Downloading sentencepiece-0.1.97-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu==2.3.1 (from -r requirements.txt (line 19))\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.26.1 (from -r requirements.txt (line 20))\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==3.20.1 (from -r requirements.txt (line 21))\n",
            "  Downloading protobuf-3.20.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi (from -r requirements.txt (line 24))\n",
            "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (1.10.13)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (2.2.5)\n",
            "Collecting uvicorn (from -r requirements.txt (line 27))\n",
            "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 30)) (1.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r requirements.txt (line 13)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r requirements.txt (line 13)) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r requirements.txt (line 13)) (2023.6.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6->-r requirements.txt (line 17)) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.14.6->-r requirements.txt (line 17))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6->-r requirements.txt (line 17)) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6->-r requirements.txt (line 17)) (3.4.1)\n",
            "Collecting multiprocess (from datasets==2.14.6->-r requirements.txt (line 17))\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6->-r requirements.txt (line 17)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6->-r requirements.txt (line 17)) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6->-r requirements.txt (line 17)) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6->-r requirements.txt (line 17)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6->-r requirements.txt (line 17)) (6.0.1)\n",
            "Collecting portalocker (from sacrebleu==2.3.1->-r requirements.txt (line 19))\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu==2.3.1->-r requirements.txt (line 19)) (0.9.0)\n",
            "Collecting colorama (from sacrebleu==2.3.1->-r requirements.txt (line 19))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu==2.3.1->-r requirements.txt (line 19)) (4.9.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.26.1->-r requirements.txt (line 20)) (3.13.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.26.1->-r requirements.txt (line 20))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 3)) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->-r requirements.txt (line 12)) (4.11.2)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->-r requirements.txt (line 24)) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->-r requirements.txt (line 24))\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions (from torch->-r requirements.txt (line 5))\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->-r requirements.txt (line 26)) (3.0.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->-r requirements.txt (line 26)) (2.1.2)\n",
            "Collecting h11>=0.8 (from uvicorn->-r requirements.txt (line 27))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->-r requirements.txt (line 24)) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->-r requirements.txt (line 24)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->-r requirements.txt (line 24)) (1.1.3)\n",
            "INFO: pip is looking at multiple versions of fsspec[http] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting fsspec[http]<=2023.10.0,>=2023.1.0 (from datasets==2.14.6->-r requirements.txt (line 17))\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 17)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 17)) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 17)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 17)) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 17)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 17)) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 5)) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.14.6->-r requirements.txt (line 17)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.14.6->-r requirements.txt (line 17)) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->-r requirements.txt (line 12)) (2.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 5)) (1.3.0)\n",
            "Building wheels for collected packages: bs4\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=5c91032d63b57f3c20c01c8d7857940e4fa72d9c4be7fdc4c6e53633e50121de\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "Successfully built bs4\n",
            "Installing collected packages: tokenizers, sentencepiece, typing-extensions, tqdm, protobuf, portalocker, h11, fsspec, dill, colorama, uvicorn, starlette, sacrebleu, multiprocess, bs4, urbans, transformers, fastapi, datasets\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.6.0\n",
            "    Uninstalling fsspec-2023.6.0:\n",
            "      Successfully uninstalled fsspec-2023.6.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.9.2 which is incompatible.\n",
            "google-ai-generativelanguage 0.3.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery 3.12.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.22.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-functions 1.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-iam 2.12.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-language 2.9.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-resource-manager 1.10.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-translate 3.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "googleapis-common-protos 1.61.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.12.7 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow 2.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bs4-0.0.1 colorama-0.4.6 datasets-2.14.6 dill-0.3.7 fastapi-0.104.1 fsspec-2023.9.2 h11-0.14.0 multiprocess-0.70.15 portalocker-2.8.2 protobuf-3.20.1 sacrebleu-2.3.1 sentencepiece-0.1.97 starlette-0.27.0 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.26.1 typing-extensions-4.8.0 urbans-0.0.1 uvicorn-0.24.0.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "project_path = os.getcwd()\n",
        "os.environ[\"PYTHONPATH\"] = f\"{os.environ.get('PYTHONPATH', '')}:{project_path}\""
      ],
      "metadata": {
        "id": "bQANoO3GJC9l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash bash/transformer.sh"
      ],
      "metadata": {
        "id": "iHigmTlBJGCG",
        "outputId": "02a7ac00-3a38-425a-f5b5-4b836ba85374",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-24 16:30:08.504183: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-24 16:30:08.504242: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-24 16:30:08.504277: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-24 16:30:08.512044: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-24 16:30:09.672127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Please install 'accelerator'\n",
            "Dataset exit!\n",
            "Initializing the model...\n",
            "LOADING LOSS FUNCTION...\n",
            "Loading dataloaders...\n",
            "===> Load data from: data/train.vi\n",
            "===> Load data from: data/train.en\n",
            "100% 133317/133317 [00:04<00:00, 31670.55it/s]\n",
            "100% 133317/133317 [00:07<00:00, 18891.12it/s]\n",
            "===> Load data from: data/validation.vi\n",
            "===> Load data from: data/validation.en\n",
            "100% 1268/1268 [00:00<00:00, 35448.05it/s]\n",
            "100% 1268/1268 [00:00<00:00, 32683.83it/s]\n",
            "Tokenization already...\n",
            "MODEL TRAINING...\n",
            "Epoch: 1\n",
            "TRAINING:   2% 130/8333 [00:39<41:26,  3.30it/s, TRAIN=Epoch 1 - Batch_Loss 0.97 - Train_Loss 1.49 - Best_Valid_Loss 100.00]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Machine-Translation-System/train.py\", line 23, in <module>\n",
            "    trainer.train()\n",
            "  File \"/content/Machine-Translation-System/model/transformer/trainer.py\", line 106, in train\n",
            "    train_losses.append(loss.item())\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash bash/mBART50.sh"
      ],
      "metadata": {
        "id": "eVLfLrPDJImX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f754383d-f14e-457e-fb22-20199c3e97c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-24 16:31:39.069960: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-24 16:31:39.070015: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-24 16:31:39.070047: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-24 16:31:39.077610: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-24 16:31:40.193133: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Please install 'accelerator'\n",
            "Dataset exit!\n",
            "LOADING METRIC...\n",
            "/content/Machine-Translation-System/model/mbart50/mbart.py:36: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  self.metric = load_metric('sacrebleu')\n",
            "Downloading builder script: 7.65kB [00:00, 15.5MB/s]       \n",
            "tokenizer_config.json: 100% 529/529 [00:00<00:00, 2.58MB/s]\n",
            "sentencepiece.bpe.model: 100% 5.07M/5.07M [00:00<00:00, 66.2MB/s]\n",
            "special_tokens_map.json: 100% 649/649 [00:00<00:00, 3.17MB/s]\n",
            "config.json: 100% 1.43k/1.43k [00:00<00:00, 8.45MB/s]\n",
            "DEVICE:  cuda\n",
            "model.safetensors: 100% 2.44G/2.44G [00:09<00:00, 260MB/s]\n",
            "generation_config.json: 100% 261/261 [00:00<00:00, 1.70MB/s]\n",
            "===> Load data from: data/train.vi\n",
            "===> Load data from: data/train.en\n",
            "===> Load data from: data/validation.vi\n",
            "===> Load data from: data/validation.en\n",
            "===> Load data from: data/test.vi\n",
            "===> Load data from: data/test.en\n",
            "MODEL EVALUATING...\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1268\n",
            "  Batch size = 16\n",
            "You're using a MBart50TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "  0% 0/80 [00:00<?, ?it/s]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "  2% 2/80 [00:03<02:18,  1.77s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "  4% 3/80 [00:06<02:39,  2.07s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "  5% 4/80 [00:08<02:50,  2.25s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "  6% 5/80 [00:12<03:34,  2.85s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "  8% 6/80 [00:16<03:57,  3.21s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "  9% 7/80 [00:20<04:19,  3.56s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 10% 8/80 [00:24<04:09,  3.47s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 11% 9/80 [00:36<07:29,  6.33s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 12% 10/80 [00:40<06:31,  5.59s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 14% 11/80 [00:45<06:11,  5.39s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 15% 12/80 [00:48<05:21,  4.73s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 16% 13/80 [00:53<05:19,  4.77s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 18% 14/80 [00:59<05:26,  4.95s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 19% 15/80 [01:03<05:16,  4.86s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 20% 16/80 [01:08<05:13,  4.90s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 21% 17/80 [01:13<05:07,  4.88s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 22% 18/80 [01:15<04:16,  4.14s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 24% 19/80 [01:20<04:11,  4.12s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 25% 20/80 [01:25<04:24,  4.40s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 26% 21/80 [01:29<04:12,  4.28s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 28% 22/80 [01:31<03:39,  3.79s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 29% 23/80 [01:34<03:21,  3.54s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 30% 24/80 [01:37<03:10,  3.41s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 31% 25/80 [01:41<03:08,  3.43s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 32% 26/80 [01:43<02:45,  3.07s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 34% 27/80 [01:46<02:37,  2.98s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 35% 28/80 [01:49<02:36,  3.01s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 36% 29/80 [01:51<02:25,  2.84s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 38% 30/80 [01:54<02:26,  2.94s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 39% 31/80 [01:58<02:28,  3.04s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 40% 32/80 [02:01<02:35,  3.23s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 41% 33/80 [02:05<02:37,  3.36s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 42% 34/80 [02:10<02:54,  3.80s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 44% 35/80 [02:13<02:41,  3.58s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 45% 36/80 [02:17<02:47,  3.80s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 46% 37/80 [02:21<02:48,  3.92s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 48% 38/80 [02:27<02:59,  4.27s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 49% 39/80 [02:31<02:52,  4.20s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 50% 40/80 [02:35<02:46,  4.17s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 51% 41/80 [02:40<02:55,  4.50s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 52% 42/80 [02:45<02:53,  4.58s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 54% 43/80 [02:51<03:02,  4.95s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 55% 44/80 [02:55<02:56,  4.90s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 56% 45/80 [03:00<02:50,  4.87s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 57% 46/80 [03:04<02:35,  4.58s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 59% 47/80 [03:08<02:28,  4.50s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 60% 48/80 [03:12<02:16,  4.26s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 61% 49/80 [03:17<02:14,  4.32s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 62% 50/80 [03:20<01:59,  3.98s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 64% 51/80 [03:23<01:53,  3.91s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 65% 52/80 [03:26<01:37,  3.48s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 66% 53/80 [03:30<01:39,  3.68s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 68% 54/80 [03:34<01:35,  3.69s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 69% 55/80 [03:38<01:32,  3.71s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 70% 56/80 [03:41<01:25,  3.56s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 71% 57/80 [03:45<01:24,  3.68s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 72% 58/80 [03:48<01:20,  3.65s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 74% 59/80 [03:51<01:13,  3.51s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 75% 60/80 [03:55<01:09,  3.47s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 76% 61/80 [03:59<01:07,  3.56s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 78% 62/80 [04:04<01:12,  4.00s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 79% 63/80 [04:09<01:15,  4.41s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 80% 64/80 [04:14<01:14,  4.64s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 81% 65/80 [04:19<01:09,  4.61s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 82% 66/80 [04:22<00:59,  4.25s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 84% 67/80 [04:28<01:01,  4.70s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 85% 68/80 [04:30<00:48,  4.07s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 86% 69/80 [04:35<00:46,  4.23s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 88% 70/80 [04:39<00:41,  4.10s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 89% 71/80 [04:42<00:35,  3.96s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 90% 72/80 [04:47<00:32,  4.09s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 91% 73/80 [04:50<00:27,  3.93s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 92% 74/80 [04:55<00:24,  4.06s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 94% 75/80 [05:01<00:23,  4.62s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 95% 76/80 [05:04<00:16,  4.21s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 96% 77/80 [05:08<00:12,  4.05s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 98% 78/80 [05:12<00:08,  4.10s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            " 99% 79/80 [05:16<00:04,  4.06s/it]Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_length\": 200,\n",
            "  \"num_beams\": 5,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "100% 80/80 [05:19<00:00,  3.99s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_A8szC8GLAwb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}